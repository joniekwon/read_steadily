# Read_steadily
꾸준히 읽기

## blog
- optimizer(AdamW, AdamRW...) [[LINK](https://hiddenbeginner.github.io/deeplearning/paperreview/2019/12/29/paper_review_AdamW.html)]

## Paper
- [Transformers in Vision: A Survey](https://arxiv.org/abs/2101.01169)
- [Transformer](https://paperswithcode.com/method/transformer)
- 
- [**Attention** Is All You Need](https://paperswithcode.com/paper/attention-is-all-you-need)
- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)

- **GRU** [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)

- [Self-Supervised Learning](https://paperswithcode.com/task/self-supervised-learning)

- [Adam](https://arxiv.org/abs/1412.6980)
- [Adadelta](https://arxiv.org/abs/1212.5701)
